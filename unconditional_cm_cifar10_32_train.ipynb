{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "984808b1d9b1472daa28fb2f62f0bc64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": "CMConfig(image_size=32, train_batch_size=32, save_image_epochs=1, save_model_epochs=1, num_samples=16, sample_steps=1, num_epochs=50, nc=10, warm_epochs=3, learning_rate=0.001, momentum=0, weight_decay=0, optimizer='RAdam', data_std=0.5, eps=0.002, T=80, s0=2, s1=150, rou=7, use_ema=True, mu0=0.9, mixed_precision='fp16', output_dir='cm\\\\unconditional_cm_cifar10_32_13', seed=213, loss_fn='L1Loss()', model_args={'model_type': 'UNet2DModel', 'model_config': {'sample_size': 32, 'in_channels': 3, 'out_channels': 3, 'layers_per_block': 2, 'block_out_channels': (128, 256, 256, 256), 'down_block_types': ('DownBlock2D', 'DownBlock2D', 'AttnDownBlock2D', 'DownBlock2D'), 'up_block_types': ('UpBlock2D', 'AttnUpBlock2D', 'UpBlock2D', 'UpBlock2D')}}, model=UNet2DModel(\n  (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (time_proj): Timesteps()\n  (time_embedding): TimestepEmbedding(\n    (linear_1): Linear(in_features=128, out_features=512, bias=True)\n    (act): SiLU()\n    (linear_2): Linear(in_features=512, out_features=512, bias=True)\n  )\n  (down_blocks): ModuleList(\n    (0): DownBlock2D(\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (1): DownBlock2D(\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (2): AttnDownBlock2D(\n      (attentions): ModuleList(\n        (0): AttentionBlock(\n          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (query): Linear(in_features=256, out_features=256, bias=True)\n          (key): Linear(in_features=256, out_features=256, bias=True)\n          (value): Linear(in_features=256, out_features=256, bias=True)\n          (proj_attn): Linear(in_features=256, out_features=256, bias=True)\n        )\n        (1): AttentionBlock(\n          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (query): Linear(in_features=256, out_features=256, bias=True)\n          (key): Linear(in_features=256, out_features=256, bias=True)\n          (value): Linear(in_features=256, out_features=256, bias=True)\n          (proj_attn): Linear(in_features=256, out_features=256, bias=True)\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (3): DownBlock2D(\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n  )\n  (up_blocks): ModuleList(\n    (0): UpBlock2D(\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (1): AttnUpBlock2D(\n      (attentions): ModuleList(\n        (0): AttentionBlock(\n          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (query): Linear(in_features=256, out_features=256, bias=True)\n          (key): Linear(in_features=256, out_features=256, bias=True)\n          (value): Linear(in_features=256, out_features=256, bias=True)\n          (proj_attn): Linear(in_features=256, out_features=256, bias=True)\n        )\n        (1): AttentionBlock(\n          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (query): Linear(in_features=256, out_features=256, bias=True)\n          (key): Linear(in_features=256, out_features=256, bias=True)\n          (value): Linear(in_features=256, out_features=256, bias=True)\n          (proj_attn): Linear(in_features=256, out_features=256, bias=True)\n        )\n        (2): AttentionBlock(\n          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (query): Linear(in_features=256, out_features=256, bias=True)\n          (key): Linear(in_features=256, out_features=256, bias=True)\n          (value): Linear(in_features=256, out_features=256, bias=True)\n          (proj_attn): Linear(in_features=256, out_features=256, bias=True)\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (2): UpBlock2D(\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n          (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (3): UpBlock2D(\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n          (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n  )\n  (mid_block): UNetMidBlock2D(\n    (attentions): ModuleList(\n      (0): AttentionBlock(\n        (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n        (query): Linear(in_features=256, out_features=256, bias=True)\n        (key): Linear(in_features=256, out_features=256, bias=True)\n        (value): Linear(in_features=256, out_features=256, bias=True)\n        (proj_attn): Linear(in_features=256, out_features=256, bias=True)\n      )\n    )\n    (resnets): ModuleList(\n      (0): ResnetBlock2D(\n        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (nonlinearity): SiLU()\n      )\n      (1): ResnetBlock2D(\n        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (nonlinearity): SiLU()\n      )\n    )\n  )\n  (conv_norm_out): GroupNorm(32, 128, eps=1e-05, affine=True)\n  (conv_act): SiLU()\n  (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n), resume_ckpt_path=None, project_name='unconditional_cm_cifar10_32', conditional=False, index2label_file_path=None, index2label={0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}, train_txt=None, valid_txt=None, test_txt=None, dataset_path=None, dataset_name='CIFAR10CMDataset', train_images_file_list=None, train_labels_list=None, valid_images_file_list=None, valid_labels_list=None, test_images_file_list=None, test_labels_list=None, train_dataset=None, train_dataloader=None, use_wandb=False, push_to_hub=False, workers=0, transforms=None, max_nums=None)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ylcm import unconditional_cifar10_cmconfig_dict, CMConfig, get_config\n",
    "config = get_config(unconditional_cifar10_cmconfig_dict, CMConfig)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "🚀yl-consistency model training starts!\n"
     ]
    },
    {
     "data": {
      "text/plain": "train : Epoch [1/50]:   0%|          | 0/1875 [00:00<?, ?it/s<class 'dict'>]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8e9a7540ddb44ee8a4a1703ea397678"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<module>\u001B[0m:\u001B[94m3\u001B[0m                                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1 \u001B[0m\u001B[94mfrom\u001B[0m \u001B[4;96mylcm\u001B[0m \u001B[94mimport\u001B[0m Consistency                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2 \u001B[0mcm = Consistency(config)                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m3 cm.train()                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m4 \u001B[0m                                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\pytorch\\github\\ylcm\\ylcm\\consistency.py\u001B[0m:\u001B[94m243\u001B[0m in \u001B[92mtrain\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m240 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[2m#反向传计算据梯度\u001B[0m                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m241 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.accelerator.backward(loss)                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m242 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[2m#调用优化器根据梯度更新模型参数\u001B[0m                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m243 \u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.optimizer.step()                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m244 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.ema_update(N)                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m245 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[2m#更新学习率，每训练一个批次学习率都会变化，学习率先会经过热身阶段从 \u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m246 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.lr_scheduler.step()                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\anaconda3\\envs\\consistency\\lib\\site-packages\\accelerate\\optimizer.py\u001B[0m:\u001B[94m133\u001B[0m in \u001B[92mstep\u001B[0m              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m130 \u001B[0m\u001B[2m│   │   │   │   \u001B[0moptimizer_args = {\u001B[33m\"\u001B[0m\u001B[33mclosure\u001B[0m\u001B[33m\"\u001B[0m: closure} \u001B[94mif\u001B[0m closure \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m \u001B[94melse\u001B[0m {}       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m131 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mxm.optimizer_step(\u001B[96mself\u001B[0m.optimizer, optimizer_args=optimizer_args)           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m132 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melif\u001B[0m \u001B[96mself\u001B[0m.scaler \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m:                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m133 \u001B[2m│   │   │   │   \u001B[0mscale_before = \u001B[96mself\u001B[0m.scaler.get_scale()                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m134 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.scaler.step(\u001B[96mself\u001B[0m.optimizer, closure)                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m135 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.scaler.update()                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m136 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mscale_after = \u001B[96mself\u001B[0m.scaler.get_scale()                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\anaconda3\\envs\\consistency\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001B[0m:\u001B[94m417\u001B[0m in \u001B[92mget_scale\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m414 \u001B[0m\u001B[2;33m│   │   │   \u001B[0m\u001B[33m:meth:`get_scale` incurs a CPU-GPU sync.\u001B[0m                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m415 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m416 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._enabled:                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m417 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._init_scale \u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._scale \u001B[95mis\u001B[0m \u001B[94mNone\u001B[0m \u001B[94melse\u001B[0m \u001B[96mself\u001B[0m._get_scale_async().   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m418 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m419 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[94m1.0\u001B[0m                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m420 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mKeyboardInterrupt\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">ylcm</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> Consistency                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>cm = Consistency(config)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 cm.train()                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\pytorch\\github\\ylcm\\ylcm\\consistency.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">243</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 │   │   │   │   │   #反向传计算据梯度</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">241 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242 │   │   │   │   │   #调用优化器根据梯度更新模型参数</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>243 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ema_update(N)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">245 │   │   │   │   │   #更新学习率，每训练一个批次学习率都会变化，学习率先会经过热身阶段从 </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">246 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lr_scheduler.step()                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\anaconda3\\envs\\consistency\\lib\\site-packages\\accelerate\\optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">133</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 │   │   │   │   </span>optimizer_args = {<span style=\"color: #808000; text-decoration-color: #808000\">\"closure\"</span>: closure} <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> closure <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> {}       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 │   │   │   │   </span>xm.optimizer_step(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer, optimizer_args=optimizer_args)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>133 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>scale_before = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.get_scale()                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.step(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer, closure)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.update()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   │   │   │   </span>scale_after = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.get_scale()                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\anaconda3\\envs\\consistency\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">417</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_scale</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">414 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">:meth:`get_scale` incurs a CPU-GPU sync.</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">416 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._enabled:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>417 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._init_scale <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._scale <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_scale_async().   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">418 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">419 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">420 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ylcm import Consistency\n",
    "cm = Consistency(config)\n",
    "cm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}